<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<html><head><title>Python: module crawler</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
</head><body bgcolor="#f0f0f8">

<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="heading">
<tr bgcolor="#7799ee">
<td valign=bottom>&nbsp;<br>
<font color="#ffffff" face="helvetica, arial">&nbsp;<br><big><big><strong>crawler</strong></big></big></font></td
><td align=right valign=bottom
><font color="#ffffff" face="helvetica, arial"><a href=".">index</a><br><a href="file:/workspaces/COMP4321_G1/src/crawler.py">/workspaces/COMP4321_G1/src/crawler.py</a></font></td></tr></table>
    <p></p>
<p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#aa55cc">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#ffffff" face="helvetica, arial"><big><strong>Modules</strong></big></font></td></tr>
    
<tr><td bgcolor="#aa55cc"><tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</tt></td><td>&nbsp;</td>
<td width="100%"><table width="100%" summary="list"><tr><td width="25%" valign=top><a href="argparse.html">argparse</a><br>
<a href="asyncio.html">asyncio</a><br>
<a href="datetime.html">datetime</a><br>
</td><td width="25%" valign=top><a href="dateutil.html">dateutil</a><br>
<a href="pydoc.html">pydoc</a><br>
<a href="re.html">re</a><br>
</td><td width="25%" valign=top><a href="requests.html">requests</a><br>
<a href="sqlite3.html">sqlite3</a><br>
<a href="urllib.html">urllib</a><br>
</td><td width="25%" valign=top></td></tr></table></td></tr></table><p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#eeaa77">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#ffffff" face="helvetica, arial"><big><strong>Functions</strong></big></font></td></tr>
    
<tr><td bgcolor="#eeaa77"><tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</tt></td><td>&nbsp;</td>
<td width="100%"><dl><dt><a name="-add_data_into_database"><strong>add_data_into_database</strong></a>(title: str, url: str, page_id: int)</dt><dd><tt>Insert&nbsp;data&nbsp;into&nbsp;the&nbsp;database.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;data&nbsp;(tuple):&nbsp;tuples&nbsp;of&nbsp;all&nbsp;necessary&nbsp;data</tt></dd></dl>
 <dl><dt><a name="-crc32"><strong>crc32</strong></a>(data, value=0, /)</dt><dd><tt>Compute&nbsp;a&nbsp;CRC-32&nbsp;checksum&nbsp;of&nbsp;data.<br>
&nbsp;<br>
&nbsp;&nbsp;value<br>
&nbsp;&nbsp;&nbsp;&nbsp;Starting&nbsp;value&nbsp;of&nbsp;the&nbsp;checksum.<br>
&nbsp;<br>
The&nbsp;returned&nbsp;checksum&nbsp;is&nbsp;an&nbsp;integer.</tt></dd></dl>
 <dl><dt><a name="-get_info_from_page"><strong>get_info_from_page</strong></a>(url, soup: bs4.BeautifulSoup, parent_url=None) -&gt; dict</dt><dd><tt>Get&nbsp;the&nbsp;info&nbsp;of&nbsp;the&nbsp;pages,&nbsp;including&nbsp;titles,&nbsp;page_ids,&nbsp;...<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;url&nbsp;(str):&nbsp;The&nbsp;url&nbsp;of&nbsp;the&nbsp;page<br>
&nbsp;&nbsp;&nbsp;&nbsp;soup&nbsp;(bsoup):&nbsp;The&nbsp;soup&nbsp;object&nbsp;of&nbsp;the&nbsp;page<br>
&nbsp;&nbsp;&nbsp;&nbsp;parent_url&nbsp;(str):&nbsp;The&nbsp;parent&nbsp;of&nbsp;this&nbsp;URL.&nbsp;If&nbsp;this&nbsp;is&nbsp;the&nbsp;root,&nbsp;then&nbsp;need&nbsp;not&nbsp;pass&nbsp;anything&nbsp;/&nbsp;Pass&nbsp;None<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;list:&nbsp;list&nbsp;of&nbsp;all&nbsp;required&nbsp;data.</tt></dd></dl>
 <dl><dt><a name="-get_soup"><strong>get_soup</strong></a>(url: str) -&gt; tuple[str, bs4.BeautifulSoup]</dt><dd><tt>Check&nbsp;the&nbsp;validity&nbsp;of&nbsp;URL,&nbsp;fix&nbsp;the&nbsp;URL&nbsp;if&nbsp;necessary.&nbsp;Get&nbsp;the&nbsp;content&nbsp;of&nbsp;the&nbsp;URL.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;url&nbsp;(str):&nbsp;The&nbsp;URL&nbsp;that&nbsp;we&nbsp;want&nbsp;to&nbsp;get&nbsp;soup&nbsp;from<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tuple:&nbsp;return&nbsp;back&nbsp;the&nbsp;fixed&nbsp;URL,&nbsp;and&nbsp;also&nbsp;the&nbsp;bsoup&nbsp;object&nbsp;of&nbsp;the&nbsp;fetched&nbsp;URL</tt></dd></dl>
 <dl><dt><a name="-get_subpage_url"><strong>get_subpage_url</strong></a>(url: str, soup: bs4.BeautifulSoup) -&gt; list</dt><dd><tt>Get&nbsp;all&nbsp;the&nbsp;URLs&nbsp;of&nbsp;the&nbsp;page.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;url&nbsp;(str):&nbsp;The&nbsp;url&nbsp;of&nbsp;the&nbsp;page<br>
&nbsp;&nbsp;&nbsp;&nbsp;soup&nbsp;(bsoup):&nbsp;The&nbsp;soup&nbsp;object&nbsp;of&nbsp;the&nbsp;page<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;list:&nbsp;list&nbsp;of&nbsp;all&nbsp;URLs&nbsp;of&nbsp;the&nbsp;page</tt></dd></dl>
 <dl><dt><a name="-main"><strong>main</strong></a>()</dt></dl>
 <dl><dt><a name="-recursively_crawl"><strong>recursively_crawl</strong></a>(num_pages: int, url: str, url_array=[])</dt><dd><tt>Insert&nbsp;data&nbsp;into&nbsp;the&nbsp;database.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;num_pages&nbsp;(int):&nbsp;Number&nbsp;of&nbsp;pages&nbsp;to&nbsp;be&nbsp;crawled<br>
&nbsp;&nbsp;&nbsp;&nbsp;url&nbsp;(str):&nbsp;The&nbsp;url&nbsp;of&nbsp;the&nbsp;page<br>
&nbsp;&nbsp;&nbsp;&nbsp;url_array:&nbsp;For&nbsp;recursion&nbsp;use&nbsp;only.&nbsp;Must&nbsp;not&nbsp;pass&nbsp;anything&nbsp;into&nbsp;it<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;None</tt></dd></dl>
</td></tr></table><p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#55aa55">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#ffffff" face="helvetica, arial"><big><strong>Data</strong></big></font></td></tr>
    
<tr><td bgcolor="#55aa55"><tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</tt></td><td>&nbsp;</td>
<td width="100%"><strong>Tuple</strong> = typing.Tuple</td></tr></table>
</body></html>